{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = \"<token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemma(question):\n",
    "    \"\"\"\n",
    "    \n",
    "    Sends a question to the Ollama API and returns the response.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='gemma:2b-instruct-v1.1-q2_K',\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': question},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Random variables** are mathematical objects that represent quantities whose values are subject to uncertainty. They are typically described by probability distributions, which specify the likelihood of different outcomes occurring.\n",
      "\n",
      "**Characteristics of Random Variables:**\n",
      "\n",
      "* **Uncertainty:** Their values are unknown until they are measured or observed.\n",
      "* **Probability distribution:** A probability distribution defines the likelihood of different outcomes occurring.\n",
      "* **Randomness:** Random variables have a random nature, meaning their values are not predetermined.\n",
      "\n",
      "**Types of Random Variables:**\n",
      "\n",
      "* **Continuous:** Values can take any value within a certain range.\n",
      "* **Discrete:** Values can only take specific integer or non-integer values.\n",
      "* **Categorical:** Values can only belong to a finite set of categories.\n",
      "\n",
      "**Examples of Random Variables:**\n",
      "\n",
      "* Coin flip\n",
      "* Temperature\n",
      "* Stock price\n",
      "* Test outcome\n",
      "\n",
      "**Uses of Random Variables:**\n",
      "\n",
      "* Statistical inference\n",
      "* Probability estimation\n",
      "* Random sampling\n",
      "* Modeling and simulation\n",
      "* Risk analysis\n",
      "\n",
      "**Properties of Probability Distributions:**\n",
      "\n",
      "* Probability mass function (PMF)\n",
      "* Probability density function (PDF)\n",
      "* Cumulative distribution function (CDF)\n",
      "* Mean, variance, standard deviation\n",
      "* Entropy\n",
      "\n",
      "**Significance of Random Variables:**\n",
      "\n",
      "Random variables play a fundamental role in probability theory and statistical inference, enabling the quantification and analysis of uncertainty in situations involving randomness.\n"
     ]
    }
   ],
   "source": [
    "response_content = ask_gemma(\"What are Random variables?\")\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Probability Theory Review for Machine Learning\\nSamuel Ieong\\nNovember 6, 2006\\n1 Basic Concepts\\nBroadly speaking, probability theory is the mathematical study of uncertainty. It plays a\\ncentral role in machine learning, as the design of learning algorithms often relies on proba-\\nbilistic assumption of the data. This set of notes attempts to cover some basic probability\\ntheory that serves as a background for the class.\\n1.1 Probability Space\\nWhen we speak about probability, we often refer to the probability of an event of uncertain\\nnature taking place. For example, we speak about the probability of rain next Tuesday.\\nTherefore, in order to discuss probability theory formally, we must ﬁrst clarify what the\\npossible events are to which we would like to attach probability.\\nFormally, a probability space is deﬁned by the triple (Ω ,F, P), where\\n•Ω is the space of possible outcomes (oroutcome space ),\\n• F ⊆ 2Ω(the power set of Ω) is the space of (measurable) events (orevent space ),\\n•Pis the probability measure (orprobability distribution ) that maps an event E∈ Fto\\na real value between 0 and 1 (think of Pas a function).\\nGiven the outcome space Ω, there is some restrictions as to what subset of 2Ωcan be\\nconsidered an event space F:\\n•The trivial event Ω and the empty event ∅is inF.\\n•The event space Fis closed under (countable) union, i.e., if α, β∈ F, then α∪β∈ F.\\n•The even space Fis closed under complement, i.e., if α∈ F, then (Ω \\\\α)∈ F.\\nExample 1. Suppose we throw a (six-sided) dice. The space of possible outcomes Ω =\\n{1,2,3,4,5,6}. We may decide that the events of interest is whether the dice throw is odd\\nor even. This event space will be given by F={∅,{1,3,5},{2,4,6},Ω}.\\n1', metadata={'source': './cs229-prob.pdf', 'page': 0}),\n",
       " Document(page_content='Note that when the outcome space Ω is ﬁnite, as in the previous example, we often take\\nthe event space Fto be 2Ω. This treatment is not fully general, but it is often suﬃcient\\nfor practical purposes. However, when the outcome space is inﬁnite, we must be careful to\\ndeﬁne what the event space is.\\nGiven an event space F, the probability measure Pmust satisfy certain axioms.\\n•(non-negativity) For all α∈ F,P(α)≥0.\\n•(trivial event) P(Ω) = 1.\\n•(additivity) For all α, β∈ Fandα∩β=∅,P(α∪β) =P(α) +P(β).\\nExample 2. Returning to our dice example, suppose we now take the event space Fto be\\n2Ω. Further, we deﬁne a probability distribution PoverFsuch that\\nP({1}) =P({2}) =···=P({6}) = 1 /6\\nthen this distribution Pcompletely speciﬁes the probability of any given event happening\\n(through the additivity axiom). For example, the probability of an even dice throw will be\\nP({2,4,6}) =P({2}) +P({4}) +P({6}) = 1 /6 + 1 /6 + 1 /6 = 1 /2\\nsince each of these events are disjoint.\\n1.2 Random Variables\\nRandom variables play an important role in probability theory. The most important fact\\nabout random variables is that they are notvariables. They are actually functions that\\nmap outcomes (in the outcome space) to real values. In terms of notation, we usually denote\\nrandom variables by a capital letter. Let’s see an example.\\nExample 3. Again, consider the process of throwing a dice. Let Xbe a random variable that\\ndepends on the outcome of the throw. A natural choice for Xwould be to map the outcome\\nito the value i, i.e., mapping the event of throwing an “one” to the value of 1. Note that\\nwe could have chosen some strange mappings too. For example, we could have a random\\nvariable Ythat maps all outcomes to 0, which would be a very boring function, or a random\\nvariable Zthat maps the outcome ito the value of 2iifiis odd and the value of −iifiis\\neven, which would be quite strange indeed.\\nIn a sense, random variables allow us to abstract away from the formal notion of event\\nspace, as we can deﬁne random variables that capture the appropriate events. For example,\\nconsider the event space of odd or even dice throw in Example 1. We could have deﬁned a\\nrandom variable that takes on value 1 if outcome iis odd and 0 otherwise. These type of\\nbinary random variables are very common in practice, and are known as indicator variables ,\\ntaking its name from its use to indicate whether a certain event has happened. So why\\ndid we introduce event space? That is because when one studies probability theory (more\\n2', metadata={'source': './cs229-prob.pdf', 'page': 1}),\n",
       " Document(page_content='rigorously) using measure theory, the distinction between outcome space and event space\\nwill be very important. This topic is too advanced to be covered in this short review note.\\nIn any case, it is good to keep in mind that event space is not always simply the power set\\nof the outcome space.\\nFrom here onwards, we will talk mostly about probability with respect to random vari-\\nables. While some probability concepts can be deﬁned meaningfully without using them,\\nrandom variables allow us to provide a more uniform treatment of probability theory. For\\nnotations, the probability of a random variable Xtaking on the value of awill be denoted\\nby either\\nP(X=a) or PX(a)\\nWe will also denote the range of a random variable XbyV al(X).\\n1.3 Distributions, Joint Distributions, and Marginal Distributions\\nWe often speak about the distribution of a variable. This formally refers to the probability\\nof a random variable taking on certain values. For example,\\nExample 4. Let random variable Xbe deﬁned on the outcome space Ωof a dice throw\\n(again!). If the dice is fair, then the distribution of Xwould be\\nPX(1) = PX(2) =···=PX(6) = 1 /6\\nNote that while this example resembles that of Example 2, they have diﬀerent semantic\\nmeaning. The probability distribution deﬁned in Example 2 is over events , whereas the one\\nhere is deﬁned over random variables .\\nFor notation, we will use P(X) to denote the distribution of the random variable X.\\nSometimes, we speak about the distribution of more than one variables at a time. We\\ncall these distributions joint distributions , as the probability is determined jointly by all the\\nvariables involved. This is best clariﬁed by an example.\\nExample 5. LetXbe a random variable deﬁned on the outcome space of a dice throw. Let\\nYbe an indicator variable that takes on value 1if a coin ﬂip turns up head and 0if tail.\\nAssuming both the dice and the coin are fair, the joint distribution of XandYis given by\\nP X= 1 X= 2 X= 3 X= 4 X= 5 X= 6\\nY= 0 1/12 1/12 1/12 1/12 1/12 1/12\\nY= 1 1/12 1/12 1/12 1/12 1/12 1/12\\nAs before, we will denote the probability of Xtaking value aandYtaking value bby\\neither the long hand of P(X=a, Y=b), or the short hand of PX,Y(a, b). We refer to their\\njoint distribution by P(X, Y).\\nGiven a joint distribution, say over random variables XandY, we can talk about the\\nmarginal distribution ofXor that of Y. The marginal distribution refers to the probability\\ndistribution of a random variable on its own. To ﬁnd out the marginal distribution of a\\n3', metadata={'source': './cs229-prob.pdf', 'page': 2}),\n",
       " Document(page_content='random variable, we sum out all the other random variables from the distribution. Formally,\\nwe mean\\nP(X) =∑\\nb∈V al(Y)P(X, Y =b) (1)\\nThe name of marginal distribution comes from the fact that if we add up all the entries\\nof a row (or a column) of a joint distribution, and write the answer at the end (i.e., margin)\\nof it, this will be the probability of the random variable taking on that value. Of course,\\nthinking in this way only helps when the joint distribution involves two variables.\\n1.4 Conditional Distributions\\nConditional distributions are one of the key tools in probability theory for reasoning about\\nuncertainty. They specify the distribution of a random variable when the value of another\\nrandom variable is known (or more generally, when some event is known to be true).\\nFormally, conditional probability of X=agiven Y=bis deﬁned as\\nP(X=a|Y=b) =P(X=a, Y=b)\\nP(Y=b)(2)\\nNote that this is not deﬁned when the probability of Y=bis 0.\\nExample 6. Suppose we know that a dice throw was odd, and want to know the probability\\nof an “one” has been thrown. Let Xbe the random variable of the dice throw, and Ybe an\\nindicator variable that takes on the value of 1if the dice throw turns up odd, then we write\\nour desired probability as follows:\\nP(X= 1|Y= 1) =P(X= 1, Y= 1)\\nP(Y= 1)=1/6\\n1/2= 1/3\\nThe idea of conditional probability extends naturally to the case when the distribution\\nof a random variable is conditioned on several variables, namely\\nP(X=a|Y=b, Z=c) =P(X=a, Y=b, Z=c)\\nP(Y=b, Z=c)\\nAs for notations, we write P(X|Y=b) to denote the distribution of random variable X\\nwhen Y=b. We may also write P(X|Y) to denote a set of distributions of X, one for each\\nof the diﬀerent values that Ycan take.\\n1.5 Independence\\nIn probability theory, independence means that the distribution of a random variable does\\nnotchange on learning the value of another random variable. In machine learning, we often\\nmake such assumptions about our data. For example, the training samples are assumed to\\n4', metadata={'source': './cs229-prob.pdf', 'page': 3}),\n",
       " Document(page_content='be drawn independently from some underlying space; the label of sample iis assumed to be\\nindependent of the features of sample j(i̸=j).\\nMathematically, a random variable Xis independent of Ywhen\\nP(X) =P(X|Y)\\n(Note that we have dropped what values XandYare taking. This means the statement\\nholds true for any values XandYmay take.)\\nUsing Equation (2), it is easy to verify that if Xis independent of Y, then Yis also\\nindependent of X. As a notation, we write X⊥YifXandYare independent.\\nAn equivalent mathematical statement about the independence of random variables X\\nandYis\\nP(X, Y) =P(X)P(Y)\\nSometimes we also talk about conditional independence , meaning that if we know the\\nvalue of a random variable (or more generally, a set of random variables), then some other\\nrandom variables will be independent of each other. Formally, we say “ XandYarecondi-\\ntionally independent given Z” if\\nP(X|Z) =P(X|Y, Z)\\nor, equivalently,\\nP(X, Y|Z) =P(X|Z)P(Y|Z)\\nAn example of conditional independence that we will se in class is the Na¨ ıve Bayes\\nassumption. This assumption is made in the context of a learning algorithm for learning to\\nclassify emails as spams or non-spams. It assumes that the probability of a word xappearing\\nin the email is conditionally independent of a word yappearing given whether the email is\\nspam or not. This clearly is not without loss of generality, as some words almost invariably\\ncomes in pair. However, as it turns out, making this simplifying assumption does not hurt\\nthe performance much, and in any case allow us to learn to classify spams rapidly. Details\\ncan be found in Lecture Notes 2.\\n1.6 Chain Rule and Bayes Rule\\nWe now present two basic yet important rules for manipulating that relates joint distributions\\nand conditional distributions. The ﬁrst is known as the Chain Rule . It can be seen as a\\ngeneralization of Equation (2) to multiple random variables.\\nTheorem 1 (Chain Rule) .\\nP(X1, X2, . . . , X n) =P(X1)P(X2|X1)···P(Xn|X1, X2, . . . , X n−1) (3)\\nThe Chain Rule is often used to evaluate the joint probability of some random variables,\\nand is especially useful when there are (conditional) independence across variables. Notice\\n5', metadata={'source': './cs229-prob.pdf', 'page': 4}),\n",
       " Document(page_content='there is a choice in the order we unravel the random variables when applying the Chain Rule;\\npicking the right order can often make evaluating the probability much easier.\\nThe second rule we are going to introduce is the Bayes Rule . The Bayes Rule allows\\nus to compute the conditional probability P(X|Y) from P(Y|X), in a sense “inverting” the\\nconditions. It can be derived simply from Equation (2) as well.\\nTheorem 2 (Bayes Rule) .\\nP(X|Y) =P(Y|X)P(X)\\nP(Y)(4)\\nAnd recall that if P(Y) is not given, we can always apply Equation (1) to ﬁnd it.\\nP(Y) =∑\\na∈V al(X)P(X=a, Y) =∑\\na∈V al(X)P(Y|X=a)P(X=a)\\nThis application of Equation (1) is sometimes referred to as the law of total probability .\\nExtending the Bayes Rule to the case of multiple random variables can sometimes be\\ntricky. Just to be clear, we would give a few examples. When in doubt, one can always refer\\nto how conditional probabilities are deﬁned and work out the details.\\nExample 7. Let’s consider the following conditional probabilities: P(X, Y|Z)and(X|Y, Z).\\nP(X, Y|Z) =P(Z|X, Y)P(X, Y)\\nP(Z)=P(Y, Z|X)P(X)\\nP(Z)\\nP(X|Y, Z) =P(Y|X, Z)P(X, Z)\\nP(Y, Z)=P(Y|X, Z)P(X|Z)P(Z)\\nP(Y|Z)P(Z)=P(Y|X, Z)P(X|Z)\\nP(Y|Z)\\n2 Deﬁning a Probability Distribution\\nWe have been talking about probability distributions for a while. But how do we deﬁne\\na distribution? In a broad sense, there are two classes of distribution that require seem-\\ningly diﬀerent treatments (these can be uniﬁed using measure theory). Namely, discrete\\ndistributions and continuous distributions. We will discuss how distributions are speciﬁed\\nnext.\\nNote that this discussion is distinct from how we can eﬃciently represent a distribution.\\nThe topic of eﬃcient representation of probability distribution is in fact a very important\\nand active research area that deserves its own course. If you are interested to learn more\\nabout how to eﬃciently represent, reason, and perform learning on distributions, you are\\nadvised to take CS228: Probabilistic Models in Artiﬁcial Intelligence.\\n2.1 Discrete Distribution: Probability Mass Function\\nBy a discrete distribution, we mean that the random variable of the underlying distribution\\ncan take on only ﬁnitely many diﬀerent values (or that the outcome space is ﬁnite).\\n6', metadata={'source': './cs229-prob.pdf', 'page': 5}),\n",
       " Document(page_content='To deﬁne a discrete distribution, we can simply enumerate the probability of the random\\nvariable taking on each of the possible values. This enumeration is known as the probability\\nmass function , as it divides up a unit mass (the total probability) and places them on the\\ndiﬀerent values a random variable can take. This can be extended analogously to joint\\ndistributions and conditional distributions.\\n2.2 Continuous Distribution: Probability Density Function\\nBy a continuous distribution, we mean that the random variable of the underlying distribu-\\ntion can take on inﬁnitely many diﬀerent values (or that the outcome space is inﬁnite).\\nThis is arguably a trickier situation than the discrete case, since if we place a non-zero\\namount of mass on each of the values, the total mass will add up to inﬁnity, which violates\\nthe requirement that the total probaiblity must sum up to one.\\nTo deﬁne a continuous distribution, we will make use of probability density function\\n(PDF). A probability density function, f, is a non-negative ,integrable function such that\\n∫\\nV al(X)f(x)dx= 1\\nThe probability of a random variable Xdistributed according to a PDF fis computed\\nas follows\\nP(a≤X≤b) =∫b\\naf(x)dx\\nNote that this, in particular, implies that the probability of a continuously distributed\\nrandom variable taking on any given single value is zero.\\nExample 8 (Uniform distribution) .Let’s consider a random variable Xthat is uniformly\\ndistributed in the range [0,1]. The corresponding PDF would be\\nf(x) ={\\n1if0≤x≤1\\n0otherwise\\nWe can verify that∫1\\n01dxis indeed 1, and therefore fis a PDF. To compute the probability\\nofXsmaller than a half,\\nP(X≤1/2) =∫1/2\\n01dx= [x]1/2\\n0= 1/2\\nMore generally, suppose Xis distributed uniformly over the range [a, b], then the PDF\\nwould be\\nf(x) ={\\n1\\nb−aifa≤x≤b\\n0 otherwise\\n7', metadata={'source': './cs229-prob.pdf', 'page': 6}),\n",
       " Document(page_content='Sometimes we will also speak about cumulative distribution function . It is a function\\nthat gives the probability of a random variable being smaller than some value. A cumulative\\ndistribution function Fis related to the underlying probability density function fas follows:\\nF(b) =P(X≤b) =∫b\\n−∞f(x)dx\\nand hence F(x) =∫\\nf(x)dx(in the sense of indeﬁnite integral).\\nTo extend the deﬁnition of continuous distribution to joint distribution, the probability\\ndensity function is extended to take multiple arguments, namely,\\nP(a1≤X1≤b1, a2≤X2≤b2, . . . , a n≤Xn≤n1) =∫b1\\na1∫b2\\na2···∫bn\\nanf(x1, x2, . . . , x n)dx1dx2. . . dx n\\nTo extend the deﬁnition of conditional distribution to continuous random variables, we\\nran into the problem that the probability of a continuous random variable taking on a single\\nvalue is 0, so Equation (2) is not well deﬁned, since the denominator equals 0. To deﬁne the\\nconditional distribution of a continuous variable, let f(x, y) be the joint distribution of X\\nandY. Through application of analysis, we can show that the PDF, f(y|x), underlying the\\ndistribution P(Y|X) is given by\\nf(y|x) =f(x, y)\\nf(x)\\nFor example,\\nP(a≤Y≤b|X=c) =∫b\\naf(y|c)dy=∫b\\naf(c, y)\\nf(c)dy\\n3 Expectations and Variance\\n3.1 Expectations\\nOne of the most common operations we perform on a random variable is to compute its\\nexpectation , also known as its mean ,expected value , orﬁrst moment . The expectation of a\\nrandom variable, denoted by E(X), is given by\\nE(X) =∑\\na∈V al(X)aP(X=a) or E(X) =∫\\na∈V al(X)xf(x)dx (5)\\nExample 9. LetXbe the outcome of rolling a fair dice. The expectation of Xis\\nE(X) = (1)1\\n6+ (2)1\\n6+···+ 61\\n6= 31\\n2\\nWe may sometimes be interested in computing the expected value of some function fof\\na random variable X. Recall, however, that a random variable is also a function itself, so\\n8', metadata={'source': './cs229-prob.pdf', 'page': 7}),\n",
       " Document(page_content='the easiest way to think about this is that we deﬁne a new random variable Y=f(X), and\\ncompute the expected value of Yinstead.\\nWhen working with indicator variables, a useful identify is the following:\\nE(X) =P(X= 1) for indicator variable X\\nWhen working with the sums of random variables, one of the most important rule is the\\nlinearity of expectations .\\nTheorem 3 (Linearity of Expectations) .LetX1,X2, . . . , Xnbe (possibly dependent) ran-\\ndom variables,\\nE(X1+X2+···+Xn) =E(X1) +E(X2) +···+E(Xn) (6)\\nThe linearity of expectations is very powerful because there are no restrictions on whether\\nthe random variables are independent or not. When we work on products of random vari-\\nables, however, there is very little we can say in general. However, when the random variables\\nare independent, then\\nTheorem 4. LetXandYbe independent random variables,\\nE(XY) =E(X)E(Y)\\n3.2 Variance\\nThevariance of a distribution is a measure of the “spread” of a distribution. Sometimes it\\nis also referred to as the second moment . It is deﬁned as follows:\\nV ar(X) =E(\\n(X−E(X))2)\\n(7)\\nThe variance of a random variable is often denoted by σ2. The reason that this is squared\\nis because we often want to ﬁnd out σ, known as the standard deviation . The variance and\\nthe standard deviation is related (obviously) by σ=√\\nV ar(X).\\nTo ﬁnd out the variance of a random variable X, it’s often easier to compute the following\\ninstead\\nV ar(X) =E(X2)−(E(X))2\\nNote that unlike expectation, variance is not a linear function of a random variable X.\\nIn fact, we can verify that the variance of ( aX+b) is\\nV ar(aX+b) =a2V ar(X)\\nIf random variables XandYare independent, then\\nV ar(X+Y) =V ar(X)V ar(Y) if X⊥Y\\nSometimes we also talk about the covariance of two random variables. This is a measure\\nof how “closely related” two random variables are. Its deﬁnition is as follows.\\nCov(X, Y) =E((X−E(X))(Y−E(Y)))\\n9', metadata={'source': './cs229-prob.pdf', 'page': 8}),\n",
       " Document(page_content='4 Some Important Distributions\\nIn this section, we will review some of the probability distributions that we will see in this\\nclass. This is by no means a comprehensive list of distribution that one should know. In\\nparticular, distributions such as the geoemtric, hypergeometric, and binomial distributions,\\nwhich are very useful in their own right and studied in introductory probability theory, are\\nnot reviewed here.\\n4.1 Bernoulli\\nTheBernoulli distribution is one of the most basic distribution. A random variable distrib-\\nuted according to the Bernoulli distribution can take on two possible values, {0,1}. It can\\nbe speciﬁed by a single parameter p, and by convention we take pto be P(X= 1). It is\\noften used to indicate whether a trail is successful or not.\\nSometimes it is useful to write the probability distribution of a Bernoulli random variable\\nXas follows\\nP(X) =px(1−p)1−x\\nAn example of the Bernoulli distribution in action is the classiﬁcation task in Lecture\\nNotes 1. To develop the logistic regression algorithm for the task, we assume that the labels\\nare distributed according to the Bernoulli distribution given the features.\\n4.2 Poisson\\nThePoisson distribution is a very useful distribution that deals with the arrival of events.\\nIt measures probaiblity of the number of events happening over a ﬁxed period of time, given\\na ﬁxed average rate of occurrence, and that the events take place independently of the time\\nsince the last event. It is parametrized by the average arrival rate λ. The probability mass\\nfunction is given by:\\nP(X=k) =exp(−λ)λk\\nk!\\nThe mean value of a Poisson random variable is λ, and its variance is also λ.\\nWe will get to work on a learning algorithm that deals with Poisson random variables in\\nHomework 1, Problem 3.\\n4.3 Gaussian\\nTheGaussian distribution , also known as the normal distribution , is one of the most “ver-\\nsatile” distributions in probability theory, and appears in a wide variety of contexts. For\\nexample, it can be used to approximate the binomial distribution when the number of ex-\\nperiments is large, or the Poisson distribution when the average arrival rate is high. It is\\nalso related to the Law of Large Numbers. For many problems, we will also often assume\\nthat when noise in the system is Gaussian distributed. The list of applications is endless.\\n10', metadata={'source': './cs229-prob.pdf', 'page': 9}),\n",
       " Document(page_content='−5 0 500.050.10.150.20.250.30.350.4\\n  \\nGaussian(0,1)\\nGaussian(1,1)\\nGaussian(0,2)Figure 1: Gaussian distributions under diﬀerent mean and variance\\nThe Gaussian distribution is determined by two parameters: the mean µand the variance\\nσ2. The probability density function is given by\\nf(x) =1√\\n2πσexp(\\n−(x−µ)2\\n2σ2)\\n(8)\\nTo get a better sense of how the distribution changes with respect to the mean and the\\nvariance, we have plotted three diﬀerent Gaussian distributions in Figure 1.\\nIn our class, we will sometimes work with multi-variate Gaussian distributions. A k-\\ndimensional multi-variate Gaussian distribution is parametrized by ( µ,Σ), where µis now a\\nvector of means inRk, and Σ is the covariance matrix inRk×k, in other words, Σ ii=V ar(Xi)\\nand Σ ij=Cov(Xi, Xj). The probability density function is now deﬁned over vectors of input,\\ngiven by\\nf(x) =1√\\n2πk|Σ|exp(\\n−1\\n2(x−µ)TΣ−1(x−µ))\\n(9)\\n(Recall that we denote the determinant of a matrix Aby|A|, and its inverse by A−1)\\nTo get a better sense of how a multi-variate Gaussian distribution depends on the covari-\\nance matrix, we can look at the ﬁgures in Lecture Notes 2, Pages 3—4.\\nWorking with a multi-variate Gaussian distribution can be tricky and daunting at times.\\nOne way to make our lives easier, at least as a way to get intuition on a problem, is to assume\\nthat the covariances are zero when we ﬁrst attempt a problem. When the covariances are\\nzero, the determinant |Σ|will simply be the product of the variances, and the inverse Σ−1\\ncan be found by taking the inverse of the diagonal entries of Σ.\\n11', metadata={'source': './cs229-prob.pdf', 'page': 10}),\n",
       " Document(page_content='5 Working with Probabilities\\nAs we will be working with probabilities and distributions a lot in this class, listed below\\nare a few tips about eﬃcient manipulation of distributions.\\n5.1 The logtrick\\nIn machine learning, we generally assume the independence of diﬀerent samples. Therefore,\\nwe often have to deal with the product of a (large) number of distributions. When our goal\\nis to optimize functions of such products, it is often easier if we ﬁrst work with the logarithm\\nof such functions. As the logarithmic function is a strictly increasing function, it will not\\ndistort where the maximum is located (although, most certainly, the maximum value of the\\nfunction before and after taking logarithm will be diﬀerent).\\nAs an example, consider the likelihood function in Lecture Notes 1, Page 17.\\nL(θ) =m∏\\ni=1(hθ(x(i)))y(i)(1−hθ(x(i)))1−y(i)\\nI dare say this is a pretty mean-looking function. But by taking the logarithm of it, termed\\nlog-likelihood function, we have instead\\nℓ(θ) = log L(θ) =m∑\\ni=1y(i)loghθ(x(i)) + (1 −y(i)) log(1 −hθ(x(i)))\\nNot the world’s prettiest function, but at least it’s more manageable. We can now work\\non one term (i.e., one training sample) at a time, because they are summed together rather\\nthan multiplied together.\\n5.2 Delayed Normalization\\nBecause probability has to sum up to one, we often have to deal with normalization, especially\\nwith continuous distribution. For example, for Gaussian distributions, the term outside of the\\nexponent is to ensure that the integral of the PDF evaluates to one. When we are sure that\\nthe end product of some algebra will be a probability distribution, or when we are ﬁnding the\\noptimum of some distributions, it’s often easier to simply denote the normalization constant\\nto be Z, and not worry about computing the normalization constant all the time.\\n5.3 Jenson’s Inequality\\nSometimes when we are evaluating the expectation of a function of a random variable, we\\nmay only need a bound rather than its exact value. In these situations, if the function is\\nconvex or concave, Jenson’s inequality allows us to derive a bound by evaluating the value\\nof the function at the expectation of the random variable itself.\\n12', metadata={'source': './cs229-prob.pdf', 'page': 11}),\n",
       " Document(page_content='0 1 2 3 4 5050100150Figure 2: Illustration of Jenson’s Inequality\\nTheorem 5 (Jenson’s Inequality) .LetXbe a random variable, and fbe a convex function.\\nThen\\nf(E(X))≤E(f(X))\\nIffis a concave function, then\\nf(E(X))≥E(f(X))\\nWhile we can show Jenson’s inequality by algebra, it’s easiest to understand it through\\na picture. The function in Figure 2 is a convex function. We can see that a straight line\\nbetween any two points on the function always lie above the function. This shows that if a\\nrandom variable can take on only two values, then Jenson’s inequality holds. It is relatively\\nstraight forward to extend this to general random variables.\\n13', metadata={'source': './cs229-prob.pdf', 'page': 12})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = docs = PyPDFLoader(file_path='./cs229-prob.pdf').load()\n",
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eda44560a3e460296134a3fb67a05d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(reader)\n",
    "chunks = filter_complex_metadata(chunks)\n",
    "\n",
    "model = ChatOllama(model=\"gemma:2b-instruct-v1.1-q2_K\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            <s> [INST] You are a helper for question answering tasks. Use the following context to answer the question. \n",
    "            If you don't know the answer, just say you don't know. Use three sentences\n",
    "             maximum and be concise in your response. [/INST] </s> \n",
    "            [INST] Question: {question} \n",
    "            Context: {context} \n",
    "            Answer: [/INST]\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "vector_store = Chroma.from_documents(documents=chunks, embedding=FastEmbedEmbeddings())\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\n",
    "                \"k\": 3,\n",
    "                \"score_threshold\": 0.5,\n",
    "            },\n",
    "        )\n",
    "\n",
    "chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "                      | prompt\n",
    "                      | model\n",
    "                      | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Random variables are functions that map outcomes to real values, allowing probability theory to handle outcomes that are not variables.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What are Random variables?\"\n",
    "\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrondza/.pyenv/versions/3.8.13/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "since each of these events are disjoint.\n",
      "1.2 Random Variables\n",
      "Random variables play an important role in probability theory. The most important fact\n",
      "about random variables is that they are notvariables. They are actually functions that\n",
      "map outcomes (in the outcome space) to real values. In terms of notation, we usually denote\n",
      "random variables by a capital letter. Let’s see an example.\n",
      "Example 3. Again, consider the process of throwing a dice. Let Xbe a random variable that\n",
      "depends on the outcome of the throw. A natural choice for Xwould be to map the outcome\n",
      "ito the value i, i.e., mapping the event of throwing an “one” to the value of 1. Note that\n",
      "we could have chosen some strange mappings too. For example, we could have a random\n",
      "variable Ythat maps all outcomes to 0, which would be a very boring function, or a random\n",
      "variable Zthat maps the outcome ito the value of 2iifiis odd and the value of −iifiis\n",
      "even, which would be quite strange indeed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "even, which would be quite strange indeed.\n",
      "In a sense, random variables allow us to abstract away from the formal notion of event\n",
      "space, as we can deﬁne random variables that capture the appropriate events. For example,\n",
      "consider the event space of odd or even dice throw in Example 1. We could have deﬁned a\n",
      "random variable that takes on value 1 if outcome iis odd and 0 otherwise. These type of\n",
      "binary random variables are very common in practice, and are known as indicator variables ,\n",
      "taking its name from its use to indicate whether a certain event has happened. So why\n",
      "did we introduce event space? That is because when one studies probability theory (more\n",
      "2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "of a random variable taking on certain values. For example,\n",
      "Example 4. Let random variable Xbe deﬁned on the outcome space Ωof a dice throw\n",
      "(again!). If the dice is fair, then the distribution of Xwould be\n",
      "PX(1) = PX(2) =···=PX(6) = 1 /6\n",
      "Note that while this example resembles that of Example 2, they have diﬀerent semantic\n",
      "meaning. The probability distribution deﬁned in Example 2 is over events , whereas the one\n",
      "here is deﬁned over random variables .\n",
      "For notation, we will use P(X) to denote the distribution of the random variable X.\n",
      "Sometimes, we speak about the distribution of more than one variables at a time. We\n",
      "call these distributions joint distributions , as the probability is determined jointly by all the\n",
      "variables involved. This is best clariﬁed by an example.\n",
      "Example 5. LetXbe a random variable deﬁned on the outcome space of a dice throw. Let\n",
      "Ybe an indicator variable that takes on value 1if a coin ﬂip turns up head and 0if tail.\n"
     ]
    }
   ],
   "source": [
    "compressor = CohereRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_reranker = ({\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "                      | prompt\n",
    "                      | model\n",
    "                      | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Random variables are functions that map outcomes to real values, allowing probability theory to be applied to events in a discrete way.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
